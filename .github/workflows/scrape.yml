name: Scrape and Aggregate

on:
  schedule:
    - cron: "36 * * * *"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: scrape
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Download existing CSV assets
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          mkdir -p data
          gh release download data -R "${{ github.repository }}" -D data -p "realmeye-full.csv" -p "realmstock-full.csv" -p "launcher-full.csv" || true

      - name: Scrape latest values
        run: bun run scrape

      - name: Upload CSV assets
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh release upload data -R "${{ github.repository }}" data/realmeye-full.csv data/realmstock-full.csv data/launcher-full.csv --clobber

      - name: Aggregate daily JSON
        run: bun run aggregate

      - name: Commit daily.json when changed
        run: |
          if git diff --quiet -- src/data/daily.json; then
            echo "No daily.json changes; skipping commit."
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add src/data/daily.json
          git commit -m "chore(data): update daily aggregation"
          git push
